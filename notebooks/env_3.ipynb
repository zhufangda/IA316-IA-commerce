{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T08:32:59.349675Z",
     "start_time": "2019-02-18T08:32:59.345674Z"
    }
   },
   "source": [
    "# Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-24T16:55:27.907281Z",
     "start_time": "2019-02-24T16:55:27.879278Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src import envs\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pandas as pd\n",
    "import requests\n",
    "from keras.layers import (Concatenate, Dense, Dot, Dropout, Embedding, Flatten,\n",
    "                          Input, Lambda)\n",
    "from keras.layers.merge import concatenate, dot\n",
    "# %load solutions/deep_implicit_feedback_recsys.py\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from itertools import product\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T08:32:42.800452Z",
     "start_time": "2019-02-18T08:32:42.796454Z"
    }
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-24T16:55:30.889017Z",
     "start_time": "2019-02-24T16:55:30.044015Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Summary-----\n",
      "key:action_history, \tsize:200, \ttype:<class 'int'>\n",
      "key:\tnb_items, \tvalue:\t30\n",
      "key:\tnb_users, \tvalue:\t100\n",
      "key:next_state, \tsize:30, \ttype:<class 'list'>\n",
      "key:rewards_history, \tsize:200, \ttype:<class 'int'>\n",
      "key:state_history, \tsize:200, \ttype:<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "data_reset = envs.req_reset(verbose=True, envs='third')\n",
    "original_df = pd.DataFrame({\n",
    "    'action': data_reset['action_history'],\n",
    "    'rewards': data_reset['rewards_history'],\n",
    "    'state': data_reset['state_history']\n",
    "})\n",
    "nb_users, nb_items = data_reset['nb_users'], data_reset['nb_items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-24T16:55:31.596018Z",
     "start_time": "2019-02-24T16:55:31.554019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Summary-----\n",
      "key:reward,\tvalue:0\n",
      "key:state,\tsize:29,\ttype:<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "data_predict = envs.req_predict(predict=0, verbose=True, envs='third')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-24T16:55:32.398561Z",
     "start_time": "2019-02-24T16:55:32.377558Z"
    }
   },
   "outputs": [],
   "source": [
    "def export_data():\n",
    "    '''\n",
    "        Export data from envs-3\n",
    "        \n",
    "        Returns:\n",
    "            nb_users: number of users\n",
    "            nb_items: number of items\n",
    "            next_state: next state\n",
    "            df : initial training set data frame\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    data_reset = envs.req_reset(verbose=False, envs='third')\n",
    "    original_data = []\n",
    "    variables = []\n",
    "    for idx in range(len(data_reset['action_history'])):\n",
    "        action = data_reset['action_history'][idx]\n",
    "        reward = data_reset['rewards_history'][idx]\n",
    "        state = data_reset['state_history'][idx]\n",
    "        \n",
    "        for idx in range(len(state)):\n",
    "            row = { 'user':state[idx][0],\n",
    "                    'item':state[idx][1],\n",
    "                    'price':state[idx][2],\n",
    "                    'reward': reward if idx == action else 0,\n",
    "                    'weight': 1 if idx == action else 0  \n",
    "                }\n",
    "\n",
    "            variables.append(state[idx][3:])\n",
    "            original_data.append(row)\n",
    "\n",
    "    variable_df = pd.DataFrame(variables, columns=['v0', 'v1', 'v2', 'v3', 'v4'])\n",
    "    data_df = pd.DataFrame(original_data)\n",
    "    variable_df.index = data_df.index \n",
    "    return data_reset['nb_users'], data_reset['nb_items'], data_reset['next_state'],pd.concat([data_df, variable_df], axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-24T16:55:33.105643Z",
     "start_time": "2019-02-24T16:55:33.069111Z"
    }
   },
   "outputs": [],
   "source": [
    "def average_roc_auc(match_model, data_train, data_test):\n",
    "    \"\"\"Compute the ROC AUC for each user and average over users\"\"\"\n",
    "    max_user = max(data_train['user'].max(), data_test['user'].max())\n",
    "    max_item = max(data_train['item'].max(), data_test['item'].max())\n",
    "    user_auc_scores = []\n",
    "    for user in range(1, max_user + 1):\n",
    "        pos_item_train = data_train[data_train['user'] == user]\n",
    "        pos_item_test = data_test[data_test['user'] == user]\n",
    "        \n",
    "        # Consider all the items already seen in the training set\n",
    "        all_items = np.arange(1, max_item + 1)\n",
    "        items_to_rank = np.setdiff1d(all_items, pos_item_train['item'].values)\n",
    "        \n",
    "        # Ground truth: return 1 for each item positively present in the test set\n",
    "        # and 0 otherwise.\n",
    "        expected = np.in1d(items_to_rank, pos_item_test['item'].values)\n",
    "        \n",
    "        if np.sum(expected) >= 1:\n",
    "            # At least one positive test value to rank\n",
    "            repeated_user = np.empty_like(items_to_rank)\n",
    "            repeated_user.fill(user)\n",
    "\n",
    "            predicted = match_model.predict([repeated_user, items_to_rank],\n",
    "                                            batch_size=4096)\n",
    "            user_auc_scores.append(roc_auc_score(expected, predicted))\n",
    "\n",
    "    return sum(user_auc_scores) / len(user_auc_scores)\n",
    "\n",
    "def sample_triplets(pos_data, random_seed=0):\n",
    "    \"\"\"Sample negatives at random\"\"\"\n",
    "    rng = np.random.RandomState(random_seed)\n",
    "    users = pos_data['user'].values\n",
    "    pos_items = pos_data[pos_data.reward>0]['item'].values\n",
    "\n",
    "    neg_items = pos_data[pos_data.reward==0]['item'].values\n",
    "\n",
    "    return [users, pos_items, neg_items]\n",
    "\n",
    "def identity_loss(y_true, y_pred):\n",
    "    \"\"\"Ignore y_true and return the mean of y_pred\n",
    "    \n",
    "    This is a hack to work-around the design of the Keras API that is\n",
    "    not really suited to train networks with a triplet loss by default.\n",
    "    \"\"\"\n",
    "    return tf.reduce_mean(y_pred + 0 * y_true)\n",
    "\n",
    "\n",
    "def margin_comparator_loss(inputs, margin=1.):\n",
    "    \"\"\"Comparator loss for a pair of precomputed similarities\n",
    "    \n",
    "    If the inputs are cosine similarities, they each have range in\n",
    "    (-1, 1), therefore their difference have range in (-2, 2). Using\n",
    "    a margin of 1. can therefore make sense.\n",
    "\n",
    "    If the input similarities are not normalized, it can be beneficial\n",
    "    to use larger values for the margin of the comparator loss.\n",
    "    \"\"\"\n",
    "    positive_pair_sim, negative_pair_sim = inputs\n",
    "    return tf.maximum(negative_pair_sim - positive_pair_sim + margin, 0)\n",
    "\n",
    "def make_interaction_mlp(input_dim, n_hidden=1, hidden_size=64,\n",
    "                         dropout=0, l2_reg=None):\n",
    "    \"\"\"Build the shared multi layer perceptron\"\"\"\n",
    "    mlp = Sequential()\n",
    "    if n_hidden == 0:\n",
    "        # Plug the output unit directly: this is a simple\n",
    "        # linear regression model. Not dropout required.\n",
    "        mlp.add(Dense(1, input_dim=input_dim,\n",
    "                      activation='relu', kernel_regularizer=l2_reg))\n",
    "    else:\n",
    "        mlp.add(Dense(hidden_size, input_dim=input_dim,\n",
    "                      activation='relu', kernel_regularizer=l2_reg))\n",
    "        mlp.add(Dropout(dropout))\n",
    "        for i in range(n_hidden - 1):\n",
    "            mlp.add(Dense(hidden_size, activation='relu',\n",
    "                          W_regularizer=l2_reg))\n",
    "            mlp.add(Dropout(dropout))\n",
    "        mlp.add(Dense(1, activation='relu', kernel_regularizer=l2_reg))\n",
    "    return mlp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T15:39:30.916577Z",
     "start_time": "2019-02-21T15:39:30.911521Z"
    }
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-24T16:55:33.773642Z",
     "start_time": "2019-02-24T16:55:33.754357Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_agent(agent, episodes,  epochs=1, online=False):\n",
    "    '''\n",
    "    Param:\n",
    "        agent : agent use to be test\n",
    "        episodes : number to test\n",
    "        \n",
    "    Returns:\n",
    "        rewards : rewards hist\n",
    "        takes : actions hist\n",
    "    '''\n",
    "    \n",
    "    total_rewards, total_takes = [], []\n",
    "    for _ in range(epochs):\n",
    "        nb_users, nb_items, next_state, hist_df = export_data()\n",
    "        agent.reset_state(nb_users, nb_items, hist_df)\n",
    "\n",
    "        rewards = []\n",
    "        takes = []\n",
    "\n",
    "        for i in tqdm(range(episodes)):\n",
    "            action = agent.predict(next_state)\n",
    "            d = envs.req_predict(0, envs='third')\n",
    "            # error for last prediction\n",
    "            rewards.append(d['reward'])\n",
    "            takes.append(d['reward'] >0)\n",
    "            # predict next\n",
    "\n",
    "            if online:\n",
    "                agent.update(next_state,  action, d['reward'])\n",
    "\n",
    "            next_state = d['state'] \n",
    "\n",
    "\n",
    "        print(f'Take Rates:{sum(takes)/len(takes)}, Mean Reawards:{sum(rewards) / len(rewards)}')\n",
    "        total_rewards.extend(rewards), total_takes.extend(takes)\n",
    "    print(f'Total Take Rates:{sum(total_takes)/len(total_takes)}, Total Mean Reawards:{sum(total_rewards) / len(total_rewards)}')\n",
    "    return total_rewards, total_takes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T13:26:11.079944Z",
     "start_time": "2019-02-23T13:26:10.237911Z"
    }
   },
   "source": [
    "## Model 1- baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-24T16:55:34.886289Z",
     "start_time": "2019-02-24T16:55:34.875240Z"
    }
   },
   "outputs": [],
   "source": [
    "class BaseAgent(object):\n",
    "    \n",
    "    def __init__(self, name='baselien'):\n",
    "        self.name = name\n",
    "    \n",
    "    \n",
    "    def reset_state(self, nb_users, nb_items, hist_df):\n",
    "        '''\n",
    "        Reset agent's model and fit model with data specified by args\n",
    "        \n",
    "        Params:\n",
    "            data : training data used to train data\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def predict(self, state):\n",
    "        '''\n",
    "        Returns action by state\n",
    "        '''\n",
    "        state = np.array(state)\n",
    "        return np.argmax(state[:,2])\n",
    "    \n",
    "    def update(self, state, action ,reward):\n",
    "        '''\n",
    "        Update model with new data.\n",
    "        This function is used for online model\n",
    "        '''\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T15:24:13.853875Z",
     "start_time": "2019-02-23T15:24:13.850878Z"
    }
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T21:22:44.590747Z",
     "start_time": "2019-02-23T21:21:18.110543Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12eeb1d6782146988ce7ae7436f443a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Take Rates:0.279, Mean Reawards:164.00504239705933\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77231677c20c43179ff086f040b1343e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Take Rates:0.291, Mean Reawards:193.30055561749262\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27905ca33d3a419d878ea04d655f5ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Take Rates:0.255, Mean Reawards:80.8419114831486\n",
      "Total Take Rates:0.275, Total Mean Reawards:146.04916983256672\n"
     ]
    }
   ],
   "source": [
    "agent1 = BaseAgent()\n",
    "reawrds, takes = test_agent(agent1, 1000, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T20:55:49.912312Z",
     "start_time": "2019-02-23T20:55:49.871314Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Agent1(BaseAgent):\n",
    "    \n",
    "    def __init__(self, epochs=50, model_params =None, verbose=False ):\n",
    "        self.epochs = epochs\n",
    "        self.verbose= verbose\n",
    "        if model_params == None:\n",
    "            self.model_params = dict(\n",
    "                user_dim=32,\n",
    "                item_dim=64,\n",
    "                n_hidden=1,\n",
    "                hidden_size=128,\n",
    "                dropout=0.1,\n",
    "                l2_reg=0\n",
    "            )\n",
    "        else:\n",
    "            self.model_params = model_params\n",
    "\n",
    "    \n",
    "         \n",
    "    def reset_state(self, nb_users, nb_items, hist_df, epoch=10):\n",
    "        ## reset data\n",
    "        self.nb_users, self.nb_items, self.hist_df = nb_users, nb_items, hist_df        \n",
    "        \n",
    "        ## extrain triple data\n",
    "        triplet_inputs = self.extraire_triple_data(self.hist_df)\n",
    "        print('Data Size:', len(triplet_inputs[0]))\n",
    "        \n",
    "        ## reset model\n",
    "        self.model, self.match_model = self._build_model(self.nb_users, self.nb_items, **self.model_params)\n",
    "        self.compile()\n",
    "        \n",
    "        ## Training model with new data\n",
    "        self.fit(triplet_inputs, epochs = self.epochs, verbose=self.verbose)\n",
    "        \n",
    "        \n",
    "    def fit(self, triplet_inputs,batch_size=64, epochs=10, verbose=True):\n",
    "        fake_y = np.ones_like( triplet_inputs[0])\n",
    "        self.model.fit(triplet_inputs, fake_y, shuffle=True,validation_split=0.1,\n",
    "                       batch_size=batch_size, epochs=epochs, verbose =verbose)\n",
    "\n",
    "        \n",
    "    def predict(self, state):\n",
    "        return np.argmax(self.predict_prob(state))\n",
    "    \n",
    "    \n",
    "    def predict_prob(self, state):\n",
    "        state = np.array(state, dtype=int)\n",
    "        user_ids = state[:,0].ravel()\n",
    "        item_ids = state[:,1].ravel()\n",
    "        return self.match_model.predict( [user_ids, item_ids])\n",
    "    \n",
    "    \n",
    "    \n",
    "    def update(self, state, action ,reward):\n",
    "        '''\n",
    "        Update model with new data.\n",
    "        This function is used for online model\n",
    "        '''\n",
    "        user_id = state[action][0]\n",
    "        item_id = state[action][1]\n",
    "\n",
    "        row = { 'user':state[action][0],\n",
    "                    'item':state[action][1],\n",
    "                    'price':state[action][2],\n",
    "                    'reward': reward,\n",
    "                    'weight': 1,\n",
    "                    'v0':state[action][3],\n",
    "                    'v1':state[action][4],\n",
    "                    'v2':state[action][5],\n",
    "                    'v3':state[action][6],\n",
    "                    'v4':state[action][7],\n",
    "                 }\n",
    "        \n",
    "        try:\n",
    "            self.hist_df = self.hist_df.append(row, ignore_index=True)\n",
    "            triplet_inputs = self.extraire_triple_data(self.hist_df[self.hist_df.user == user_id])\n",
    "            \n",
    "            if len(triplet_inputs[0]) == 0:\n",
    "                return\n",
    "            self.fit(triplet_inputs, epochs = 1, verbose=self.verbose)\n",
    "        except Exception as e:\n",
    "            print('user_id:', user_id)\n",
    "            print(state)\n",
    "            print(triplet_inputs)\n",
    "            raise Exception(e)\n",
    "\n",
    "            \n",
    "            \n",
    "        \n",
    "    def _build_model(self, n_users=32, n_items=64, user_dim=32, item_dim=64,\n",
    "                     n_hidden=3, hidden_size=64, dropout=0, l2_reg=0):\n",
    "        \n",
    "        user_input = Input((1,), name='user_input')\n",
    "        positive_item_input = Input((1,), name='positive_item_input')\n",
    "        negative_item_input = Input((1,), name='negative_item_input')\n",
    "\n",
    "        # - embeddings\n",
    "        l2_reg = None if l2_reg == 0 else l2(l2_reg)\n",
    "        user_layer = Embedding(n_users, user_dim, input_length=1,\n",
    "                               name='user_embedding', embeddings_regularizer=l2_reg)\n",
    "        user_embedding = Flatten()(user_layer(user_input))\n",
    "\n",
    "        item_layer = Embedding(n_items, item_dim, input_length=1,\n",
    "                               name=\"item_embedding\", embeddings_regularizer=l2_reg)\n",
    "\n",
    "        positive_item_embedding = Flatten()(item_layer(positive_item_input))\n",
    "        negative_item_embedding = Flatten()(item_layer(negative_item_input))\n",
    "\n",
    "        positive_embeddings_pair = concatenate([user_embedding, positive_item_embedding],\n",
    "                                         name=\"positive_embeddings_pair\")\n",
    "        positive_embeddings_pair = Dropout(dropout)(positive_embeddings_pair)\n",
    "\n",
    "        negative_embeddings_pair = concatenate([user_embedding, negative_item_embedding],\n",
    "\n",
    "                                         name=\"negative_embeddings_pair\")\n",
    "        negative_embeddings_pair = Dropout(dropout)(negative_embeddings_pair)\n",
    "\n",
    "\n",
    "        interaction_layers = make_interaction_mlp(\n",
    "            user_dim + item_dim, n_hidden=n_hidden, hidden_size=hidden_size,\n",
    "            dropout=dropout, l2_reg=l2_reg)\n",
    "\n",
    "        positive_mlp = interaction_layers(positive_embeddings_pair)\n",
    "        negative_mlp = interaction_layers(negative_embeddings_pair)\n",
    "\n",
    "        # The triplet network model, only used for training\n",
    "        triplet_loss = Lambda(margin_comparator_loss,\n",
    "                              name='comparator_loss',\n",
    "                              output_shape=(1,))(\n",
    "            [positive_mlp, negative_mlp])\n",
    "        \n",
    "        match_model = Model(inputs=[user_input, positive_item_input],\n",
    "                    outputs=positive_mlp)\n",
    "\n",
    "        model = Model(inputs=[user_input,\n",
    "                                      positive_item_input,\n",
    "                                      negative_item_input],\n",
    "                              outputs=triplet_loss)\n",
    "\n",
    "        return model, match_model\n",
    "     \n",
    "    \n",
    "    def extraire_triple_data(self, df):\n",
    "        '''\n",
    "        Extrait training data\n",
    "        \n",
    "        '''\n",
    "        grouped = df.groupby(by='user')\n",
    "        all_items = set(range(nb_items))\n",
    "\n",
    "        users, pos_items, neg_items = [], [], []\n",
    "        for idx, ele in grouped:\n",
    "            user_id = idx\n",
    "            pos_ids = ele[ele.reward>0]['item'].values\n",
    "            neg_ids = ele[ele.reward == 0]['item'].values\n",
    "            product_list = list(zip(*list(product([user_id], pos_ids, neg_ids))))\n",
    "            \n",
    "            if len(product_list) == 0:\n",
    "                continue\n",
    "#             print(idx, pos_ids.shape, neg_ids.shape, len(product_list[0]))\n",
    "            users.extend(product_list[0])\n",
    "            pos_items.extend(product_list[1])\n",
    "            neg_items.extend(product_list[2])\n",
    "        \n",
    "#         print(len(users))\n",
    "        assert len(users) == len(pos_items)\n",
    "        assert len(users) == len(neg_items)\n",
    "        return [users, pos_items, neg_items]\n",
    "    \n",
    "    \n",
    "\n",
    "    def compile(self, loss=identity_loss, optimizer='adam'):\n",
    "        self.model.compile(loss=loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T15:24:11.572877Z",
     "start_time": "2019-02-23T15:24:11.568884Z"
    }
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T21:23:34.301892Z",
     "start_time": "2019-02-23T21:23:14.060876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 6246\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfbbb1ddc7614576a51fc61b00d233d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Take Rates:0.3, Mean Reawards:62.003374130728766\n",
      "Data Size: 4571\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea539fa04efc4a85a500185798bc6a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Take Rates:0.2, Mean Reawards:46.74600391144957\n",
      "Total Take Rates:0.25, Total Mean Reawards:54.37468902108917\n"
     ]
    }
   ],
   "source": [
    "agent11 = Agent1(epochs=10, verbose=False)\n",
    "rewards, takes = test_agent(agent11, 10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T21:28:08.576168Z",
     "start_time": "2019-02-23T21:23:36.178890Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 4718\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf0f72bf4ce41009d5ef50a9b8a2ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Take Rates:0.287, Mean Reawards:180.1074579813299\n",
      "Data Size: 4133\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ea92c6e9e744f599b1681515c0e4b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Take Rates:0.266, Mean Reawards:179.29623833926226\n",
      "Data Size: 4987\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98e10b6f67a47e8848f01a743f2332c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Take Rates:0.316, Mean Reawards:231.57568127382433\n",
      "Total Take Rates:0.2896666666666667, Total Mean Reawards:196.9931258648048\n"
     ]
    }
   ],
   "source": [
    "agent12 = Agent1(epochs=10, verbose=False)\n",
    "rewards, takes = test_agent(agent12, 1000, 3, online=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T21:28:10.503194Z",
     "start_time": "2019-02-23T21:28:10.457177Z"
    }
   },
   "outputs": [],
   "source": [
    "class Agent2(BaseAgent):\n",
    "    \n",
    "    def __init__(self, epochs=50, model_params =None, verbose=False ):\n",
    "        self.epochs = epochs\n",
    "        self.verbose= verbose\n",
    "        if model_params == None:\n",
    "            self.model_params = dict(\n",
    "                user_dim=32,\n",
    "                item_dim=64,\n",
    "                n_hidden=1,\n",
    "                hidden_size=128,\n",
    "                dropout=0.1,\n",
    "                l2_reg=0\n",
    "            )\n",
    "        else:\n",
    "            self.model_params = model_params\n",
    "\n",
    "    \n",
    "         \n",
    "    def reset_state(self, nb_users, nb_items, hist_df, epoch=10):\n",
    "        ## reset data\n",
    "        self.nb_users, self.nb_items, self.hist_df = nb_users, nb_items, hist_df        \n",
    "        \n",
    "        ## extrain triple data\n",
    "        print('Extract Data ......')\n",
    "        triplet_inputs = self.extraire_triple_data(self.hist_df)\n",
    "        print('Data Size:', len(triplet_inputs[0]))\n",
    "        \n",
    "        ## reset model\n",
    "        print('Create Model ......')\n",
    "        self.model, self.match_model = self._build_model(self.nb_users, self.nb_items, **self.model_params)\n",
    "        self.compile()\n",
    "        \n",
    "        ## Training model with new data\n",
    "        print('Fit Model ......')\n",
    "        self.fit(triplet_inputs, epochs = self.epochs, verbose=self.verbose)\n",
    "        \n",
    "        \n",
    "    def fit(self, triplet_inputs,batch_size=64, epochs=10, verbose=True):\n",
    "        fake_y = np.ones_like( triplet_inputs[0])\n",
    "        self.model.fit(triplet_inputs, fake_y, shuffle=True,\n",
    "                       batch_size=batch_size, epochs=epochs, verbose=verbose)\n",
    "\n",
    "        \n",
    "    def predict(self, state):\n",
    "        return np.argmax(self.predict_prob(state))\n",
    "    \n",
    "    \n",
    "    def predict_prob(self, state):\n",
    "        state = np.array(state, dtype=int)\n",
    "        user_ids = state[:,0].ravel()\n",
    "        item_ids = state[:,1].ravel()\n",
    "        meta_vec = state[:,3:]\n",
    "        \n",
    "        return self.match_model.predict( [user_ids, item_ids, meta_vec])\n",
    "    \n",
    "    \n",
    "    \n",
    "    def update(self, state, action ,reward):\n",
    "        '''\n",
    "        Update model with new data.\n",
    "        This function is used for online model\n",
    "        '''\n",
    "        user_id = state[action][0]\n",
    "        item_id = state[action][1]\n",
    "\n",
    "        row = { 'user':state[action][0],\n",
    "                    'item':state[action][1],\n",
    "                    'price':state[action][2],\n",
    "                    'reward': reward,\n",
    "                    'weight': 1,\n",
    "                    'v0':state[action][3],\n",
    "                    'v1':state[action][4],\n",
    "                    'v2':state[action][5],\n",
    "                    'v3':state[action][6],\n",
    "                    'v4':state[action][7],\n",
    "                 }\n",
    "        try:\n",
    "            self.hist_df = self.hist_df.append(row, ignore_index=True)\n",
    "            triplet_inputs = self.extraire_triple_data(self.hist_df[self.hist_df.user == user_id])\n",
    "            \n",
    "            if triplet_inputs == None or len(triplet_inputs[0]) == 0:\n",
    "                return\n",
    "            self.fit(triplet_inputs, epochs = 1, verbose=self.verbose)\n",
    "        except Exception as e:\n",
    "            print(('user_id:', user_id))\n",
    "            print(state)\n",
    "            print(triplet_inputs)\n",
    "            raise Exception(e)\n",
    "\n",
    "            \n",
    "            \n",
    "        \n",
    "    def _build_model(self, n_users=32, n_items=64, user_dim=32, item_dim=64,\n",
    "                     n_hidden=3, hidden_size=64, dropout=0, l2_reg=0):\n",
    "        \n",
    "        user_input = Input((1,), name='user_input')\n",
    "        positive_item_input = Input((1,), name='positive_item_input')\n",
    "        positive_meta_input = Input((5,), name='positive_meta_item')\n",
    "        negative_item_input = Input((1,), name='negative_item_input')\n",
    "        negative_meta_input = Input((5,), name='negative_meta_input')\n",
    "        \n",
    "\n",
    "        # - embeddings\n",
    "        l2_reg = None if l2_reg == 0 else l2(l2_reg)\n",
    "        user_layer = Embedding(n_users, user_dim, input_length=1,\n",
    "                               name='user_embedding', embeddings_regularizer=l2_reg)\n",
    "        user_embedding = Flatten()(user_layer(user_input))\n",
    "\n",
    "        item_layer = Embedding(n_items, item_dim, input_length=1,\n",
    "                               name=\"item_embedding\", embeddings_regularizer=l2_reg)\n",
    "\n",
    "        positive_item_embedding = Flatten()(item_layer(positive_item_input))\n",
    "        negative_item_embedding = Flatten()(item_layer(negative_item_input))\n",
    "\n",
    "        positive_embeddings_pair = concatenate([user_embedding, positive_item_embedding, positive_meta_input],\n",
    "                                         name=\"positive_embeddings_pair\")\n",
    "        positive_embeddings_pair = Dropout(dropout)(positive_embeddings_pair)\n",
    "\n",
    "        negative_embeddings_pair = concatenate([user_embedding, negative_item_embedding, negative_meta_input],\n",
    "\n",
    "                                         name=\"negative_embeddings_pair\")\n",
    "        negative_embeddings_pair = Dropout(dropout)(negative_embeddings_pair)\n",
    "\n",
    "\n",
    "        interaction_layers = make_interaction_mlp(\n",
    "            user_dim + item_dim + 5, n_hidden=n_hidden, hidden_size=hidden_size,\n",
    "            dropout=dropout, l2_reg=l2_reg)\n",
    "\n",
    "        positive_mlp = interaction_layers(positive_embeddings_pair)\n",
    "        negative_mlp = interaction_layers(negative_embeddings_pair)\n",
    "\n",
    "        # The triplet network model, only used for training\n",
    "        triplet_loss = Lambda(margin_comparator_loss,\n",
    "                              name='comparator_loss',\n",
    "                              output_shape=(1,))(\n",
    "            [positive_mlp, negative_mlp])\n",
    "        \n",
    "        match_model = Model(inputs=[user_input, positive_item_input, positive_meta_input],\n",
    "                    outputs=positive_mlp)\n",
    "\n",
    "        model = Model(inputs=[user_input,\n",
    "                              positive_item_input,\n",
    "                              positive_meta_input,\n",
    "                              negative_item_input,\n",
    "                              negative_meta_input\n",
    "                             ],\n",
    "                              outputs=triplet_loss)\n",
    "\n",
    "        return model, match_model\n",
    "     \n",
    "    \n",
    "    def extraire_triple_data(self, df):\n",
    "        '''\n",
    "        Extrait training data\n",
    "        \n",
    "        '''\n",
    "        pos_grouped = df.groupby(by='user')\n",
    "        all_items = set(range(self.nb_items))\n",
    "    \n",
    "        users, pos_items,pos_meta, neg_items, neg_meta = [], [], [],[], []\n",
    "        for idx, ele in pos_grouped:\n",
    "            pos_rows = ele[ele['reward']>0].values\n",
    "            neg_rows = ele[ele['reward'] == 0.0].values\n",
    "            product_list = list(zip(*list(product(pos_rows, neg_rows))))\n",
    "        #     pos_id = .extend(product_list[1])\n",
    "            if len(product_list) == 0:\n",
    "                continue\n",
    "#             print(len(product_list))\n",
    "            pos_rows = np.array(product_list[0])\n",
    "            neg_rows = np.array(product_list[1])\n",
    "#             print(pos_rows.shape)\n",
    "           \n",
    "#             pos_rows = product_list[1]\n",
    "            users.append(pos_rows[:,0])\n",
    "            pos_items.append(pos_rows[:,1])\n",
    "            pos_meta.append(pos_rows[:,-5:])\n",
    "            neg_items.append(neg_rows[:,1])\n",
    "            neg_meta.append(neg_rows[:,-5:])\n",
    "#             print((idx, pos_rows[:,0].shape, pos_rows[:,1].shape, pos_rows[:,-5:].shape, neg_rows[:,1].shape, neg_rows[:,-5:].shape))\n",
    "\n",
    "#             break\n",
    "#             for ele in product_list[0]:\n",
    "#                 pos_items.append(ele[0])\n",
    "#                 pos_meta.append(ele[1:])\n",
    "#                 users.append(idx)\n",
    "\n",
    "#             for ele in product_list[1]:\n",
    "#                 neg_items.append(ele[0])\n",
    "#                 neg_meta.append(ele[1:])\n",
    "                \n",
    "            assert len(users) == len(pos_items)\n",
    "            assert len(users) == len(pos_meta)\n",
    "            assert len(users) == len(neg_items)\n",
    "            assert len(users) == len(pos_meta)\n",
    "            \n",
    "        if len(users) == 0:\n",
    "            return None\n",
    "        return [np.concatenate(users), np.concatenate(pos_items),np.vstack(pos_meta), np.concatenate(neg_items), np.vstack(neg_meta)]\n",
    "            \n",
    "#         return [users, pos_items, pos_meta,  neg_items, neg_meta]\n",
    "    \n",
    "\n",
    "    def compile(self, loss=identity_loss, optimizer='adam'):\n",
    "        self.model.compile(loss=loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T21:28:44.070011Z",
     "start_time": "2019-02-23T21:28:12.382170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract Data ......\n",
      "Data Size: 5504\n",
      "Create Model ......\n",
      "Fit Model ......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e59f0e5691446e2a95cf610418d772b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Take Rates:0.5, Mean Reawards:453.60797250448843\n",
      "Extract Data ......\n",
      "Data Size: 4790\n",
      "Create Model ......\n",
      "Fit Model ......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a668f31faf14858b861c2fc99d2f094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Take Rates:0.5, Mean Reawards:139.2829113482531\n",
      "Extract Data ......\n",
      "Data Size: 4906\n",
      "Create Model ......\n",
      "Fit Model ......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73eda3e363834173ac269cc7db0f4618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Take Rates:0.2, Mean Reawards:117.5164682743065\n",
      "Total Take Rates:0.4, Total Mean Reawards:236.80245070901597\n"
     ]
    }
   ],
   "source": [
    "agent21 = Agent2(epochs=10, verbose=False)\n",
    "rewards, takes = test_agent(agent21, 10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-23T21:33:15.939308Z",
     "start_time": "2019-02-23T21:28:46.180016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract Data ......\n",
      "Data Size: 4684\n",
      "Create Model ......\n",
      "Fit Model ......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52313b4829cd43bd849daa48e468b839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Take Rates:0.309, Mean Reawards:162.66470323321778\n",
      "Extract Data ......\n",
      "Data Size: 4428\n",
      "Create Model ......\n",
      "Fit Model ......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe364f406fc4193bf9234a06debaba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Take Rates:0.36, Mean Reawards:213.4542842387859\n",
      "Extract Data ......\n",
      "Data Size: 4232\n",
      "Create Model ......\n",
      "Fit Model ......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f33659da3084e78abf44aa66e3a4ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Take Rates:0.275, Mean Reawards:147.32685177461937\n",
      "Total Take Rates:0.31466666666666665, Total Mean Reawards:174.48194641554093\n"
     ]
    }
   ],
   "source": [
    "agent21 = Agent2(epochs=10, verbose=False)\n",
    "rewards, takes = test_agent(agent21, 1000, 3, online=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent2(BaseAgent):\n",
    "    \n",
    "    def __init__(self, epochs=50, model_params =None, verbose=False ):\n",
    "        self.epochs = epochs\n",
    "        self.verbose= verbose\n",
    "        if model_params == None:\n",
    "            self.model_params = dict(\n",
    "                user_dim=32,\n",
    "                item_dim=64,\n",
    "                n_hidden=1,\n",
    "                hidden_size=128,\n",
    "                dropout=0.1,\n",
    "                l2_reg=0\n",
    "            )\n",
    "        else:\n",
    "            self.model_params = model_params\n",
    "\n",
    "    \n",
    "         \n",
    "    def reset_state(self, nb_users, nb_items, hist_df, epoch=10):\n",
    "        ## reset data\n",
    "        self.nb_users, self.nb_items, self.hist_df = nb_users, nb_items, hist_df        \n",
    "        \n",
    "        ## extrain triple data\n",
    "        print('Extract Data ......')\n",
    "        triplet_inputs = self.extraire_triple_data(self.hist_df)\n",
    "        print('Data Size:', len(triplet_inputs[0]))\n",
    "        \n",
    "        ## reset model\n",
    "        print('Create Model ......')\n",
    "        self.model, self.match_model = self._build_model(self.nb_users, self.nb_items, **self.model_params)\n",
    "        self.compile()\n",
    "        \n",
    "        ## Training model with new data\n",
    "        print('Fit Model ......')\n",
    "        self.fit(triplet_inputs, epochs = self.epochs, verbose=self.verbose)\n",
    "        \n",
    "        \n",
    "    def fit(self, triplet_inputs,batch_size=64, epochs=10, verbose=True):\n",
    "        fake_y = np.ones_like( triplet_inputs[0])\n",
    "        self.model.fit(triplet_inputs, fake_y, shuffle=True,\n",
    "                       batch_size=batch_size, epochs=epochs, verbose=verbose)\n",
    "\n",
    "        \n",
    "    def predict(self, state):\n",
    "        return np.argmax(self.predict_prob(state))\n",
    "    \n",
    "    \n",
    "    def predict_prob(self, state):\n",
    "        state = np.array(state, dtype=int)\n",
    "        user_ids = state[:,0].ravel()\n",
    "        item_ids = state[:,1].ravel()\n",
    "        meta_vec = state[:,3:]\n",
    "        \n",
    "        return self.match_model.predict( [user_ids, item_ids, meta_vec])\n",
    "    \n",
    "    \n",
    "    \n",
    "    def update(self, state, action ,reward):\n",
    "        '''\n",
    "        Update model with new data.\n",
    "        This function is used for online model\n",
    "        '''\n",
    "        user_id = state[action][0]\n",
    "        item_id = state[action][1]\n",
    "\n",
    "        row = { 'user':state[action][0],\n",
    "                    'item':state[action][1],\n",
    "                    'price':state[action][2],\n",
    "                    'reward': reward,\n",
    "                    'weight': 1,\n",
    "                    'v0':state[action][3],\n",
    "                    'v1':state[action][4],\n",
    "                    'v2':state[action][5],\n",
    "                    'v3':state[action][6],\n",
    "                    'v4':state[action][7],\n",
    "                 }\n",
    "        try:\n",
    "            self.hist_df = self.hist_df.append(row, ignore_index=True)\n",
    "            triplet_inputs = self.extraire_triple_data(self.hist_df[self.hist_df.user == user_id])\n",
    "            \n",
    "            if triplet_inputs == None or len(triplet_inputs[0]) == 0:\n",
    "                return\n",
    "            self.fit(triplet_inputs, epochs = 1, verbose=self.verbose)\n",
    "        except Exception as e:\n",
    "            print(('user_id:', user_id))\n",
    "            print(state)\n",
    "            print(triplet_inputs)\n",
    "            raise Exception(e)\n",
    "\n",
    "            \n",
    "            \n",
    "        \n",
    "    def _build_model(self, n_users=32, n_items=64, user_dim=32, item_dim=64,\n",
    "                     n_hidden=3, hidden_size=64, dropout=0, l2_reg=0):\n",
    "        \n",
    "        user_input = Input((1,), name='user_input')\n",
    "        positive_item_input = Input((1,), name='positive_item_input')\n",
    "        positive_meta_input = Input((5,), name='positive_meta_item')\n",
    "        negative_item_input = Input((1,), name='negative_item_input')\n",
    "        negative_meta_input = Input((5,), name='negative_meta_input')\n",
    "        \n",
    "\n",
    "        # - embeddings\n",
    "        l2_reg = None if l2_reg == 0 else l2(l2_reg)\n",
    "        user_layer = Embedding(n_users, user_dim, input_length=1,\n",
    "                               name='user_embedding', embeddings_regularizer=l2_reg)\n",
    "        user_embedding = Flatten()(user_layer(user_input))\n",
    "\n",
    "        item_layer = Embedding(n_items, item_dim, input_length=1,\n",
    "                               name=\"item_embedding\", embeddings_regularizer=l2_reg)\n",
    "\n",
    "        positive_item_embedding = Flatten()(item_layer(positive_item_input))\n",
    "        negative_item_embedding = Flatten()(item_layer(negative_item_input))\n",
    "\n",
    "        positive_embeddings_pair = concatenate([user_embedding, positive_item_embedding, positive_meta_input],\n",
    "                                         name=\"positive_embeddings_pair\")\n",
    "        positive_embeddings_pair = Dropout(dropout)(positive_embeddings_pair)\n",
    "\n",
    "        negative_embeddings_pair = concatenate([user_embedding, negative_item_embedding, negative_meta_input],\n",
    "\n",
    "                                         name=\"negative_embeddings_pair\")\n",
    "        negative_embeddings_pair = Dropout(dropout)(negative_embeddings_pair)\n",
    "\n",
    "\n",
    "        interaction_layers = make_interaction_mlp(\n",
    "            user_dim + item_dim + 5, n_hidden=n_hidden, hidden_size=hidden_size,\n",
    "            dropout=dropout, l2_reg=l2_reg)\n",
    "\n",
    "        positive_mlp = interaction_layers(positive_embeddings_pair)\n",
    "        negative_mlp = interaction_layers(negative_embeddings_pair)\n",
    "\n",
    "        # The triplet network model, only used for training\n",
    "        triplet_loss = Lambda(margin_comparator_loss,\n",
    "                              name='comparator_loss',\n",
    "                              output_shape=(1,))(\n",
    "            [positive_mlp, negative_mlp])\n",
    "        \n",
    "        match_model = Model(inputs=[user_input, positive_item_input, positive_meta_input],\n",
    "                    outputs=positive_mlp)\n",
    "\n",
    "        model = Model(inputs=[user_input,\n",
    "                              positive_item_input,\n",
    "                              positive_meta_input,\n",
    "                              negative_item_input,\n",
    "                              negative_meta_input\n",
    "                             ],\n",
    "                              outputs=triplet_loss)\n",
    "\n",
    "        return model, match_model\n",
    "     \n",
    "    \n",
    "    def extraire_triple_data(self, df):\n",
    "        '''\n",
    "        Extrait training data\n",
    "        \n",
    "        '''\n",
    "        pos_grouped = df.groupby(by='user')\n",
    "        all_items = set(range(self.nb_items))\n",
    "    \n",
    "        users, pos_items,pos_meta, neg_items, neg_meta = [], [], [],[], []\n",
    "        for idx, ele in pos_grouped:\n",
    "            pos_rows = ele[ele['reward']>0].values\n",
    "            neg_rows = ele[ele['reward'] == 0.0].values\n",
    "            product_list = list(zip(*list(product(pos_rows, neg_rows))))\n",
    "        #     pos_id = .extend(product_list[1])\n",
    "            if len(product_list) == 0:\n",
    "                continue\n",
    "#             print(len(product_list))\n",
    "            pos_rows = np.array(product_list[0])\n",
    "            neg_rows = np.array(product_list[1])\n",
    "#             print(pos_rows.shape)\n",
    "           \n",
    "#             pos_rows = product_list[1]\n",
    "            users.append(pos_rows[:,0])\n",
    "            pos_items.append(pos_rows[:,1])\n",
    "            pos_meta.append(pos_rows[:,-5:])\n",
    "            neg_items.append(neg_rows[:,1])\n",
    "            neg_meta.append(neg_rows[:,-5:])\n",
    "#             print((idx, pos_rows[:,0].shape, pos_rows[:,1].shape, pos_rows[:,-5:].shape, neg_rows[:,1].shape, neg_rows[:,-5:].shape))\n",
    "\n",
    "#             break\n",
    "#             for ele in product_list[0]:\n",
    "#                 pos_items.append(ele[0])\n",
    "#                 pos_meta.append(ele[1:])\n",
    "#                 users.append(idx)\n",
    "\n",
    "#             for ele in product_list[1]:\n",
    "#                 neg_items.append(ele[0])\n",
    "#                 neg_meta.append(ele[1:])\n",
    "                \n",
    "            assert len(users) == len(pos_items)\n",
    "            assert len(users) == len(pos_meta)\n",
    "            assert len(users) == len(neg_items)\n",
    "            assert len(users) == len(pos_meta)\n",
    "            \n",
    "        if len(users) == 0:\n",
    "            return None\n",
    "        return [np.concatenate(users), np.concatenate(pos_items),np.vstack(pos_meta), np.concatenate(neg_items), np.vstack(neg_meta)]\n",
    "            \n",
    "#         return [users, pos_items, pos_meta,  neg_items, neg_meta]\n",
    "    \n",
    "\n",
    "    def compile(self, loss=identity_loss, optimizer='adam'):\n",
    "        self.model.compile(loss=loss, optimizer=optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_gpu]",
   "language": "python",
   "name": "conda-env-tf_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "706.364px",
    "left": "595px",
    "top": "110.284px",
    "width": "349.075px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
