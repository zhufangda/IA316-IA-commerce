{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from envs import *\n",
    "\n",
    "from tensorflow.contrib import keras\n",
    "from keras.layers import Input, Embedding, Flatten, Dense, Dropout\n",
    "from keras.layers import Dot, Concatenate, Activation\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "from time import sleep\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env_2:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data = req_reset(envs='second', verbose=False)\n",
    "        self.n_model = 0\n",
    "    \n",
    "    def fit_model_1(self):\n",
    "        \"\"\"\n",
    "        embedding model, with inputs of \"user_id\", \"item_id\" and \"variables\"\n",
    "        \"\"\"\n",
    "        self.n_model = 1\n",
    "        \n",
    "        user_id_input = Input(shape=[1], name='user')\n",
    "        item_id_input = Input(shape=[1], name='item')\n",
    "        variables_input = Input(shape=[5], name='variables')\n",
    "\n",
    "        embedding_size = 32\n",
    "        user_embedding = Embedding(output_dim=embedding_size, input_dim=2000,\n",
    "                           input_length=1, name='user_embedding')(user_id_input)\n",
    "        item_embedding = Embedding(output_dim=embedding_size, input_dim=2000,\n",
    "                           input_length=1, name='item_embedding')(item_id_input)\n",
    "\n",
    "        user_vecs = Flatten()(user_embedding)\n",
    "        item_vecs = Flatten()(item_embedding)\n",
    "\n",
    "        concatenated = Concatenate(axis=-1)([user_vecs, item_vecs, variables_input])\n",
    "        concatenated = Dense(32, activation='relu')(concatenated)\n",
    "        concatenated = Dropout(0.5)(concatenated)\n",
    "        outputs = Dense(1)(concatenated)\n",
    "\n",
    "        self.model = Model(inputs=[user_id_input, item_id_input, variables_input], outputs=outputs)\n",
    "        self.model.compile(optimizer='adam', loss='mse')\n",
    "        \n",
    "        X = [self.data['user_history'], self.data['item_history'], self.data['variables_history']]\n",
    "        y = self.data['rating_history']\n",
    "        \n",
    "        self.model.fit(X, y, epochs=50, verbose=False)\n",
    "        return\n",
    "    \n",
    "    def fit_model_2(self):\n",
    "        \"\"\"\n",
    "        sequential model, only use \"variables\" as the input\n",
    "        \"\"\"\n",
    "        self.n_model = 2\n",
    "        \n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(5,input_dim=5, activation='relu'))\n",
    "        self.model.add(Dropout(0.25))\n",
    "        self.model.add(Dense(2, activation='relu'))\n",
    "        self.model.add(Dropout(0.25))\n",
    "        self.model.add(Dense(1))\n",
    "\n",
    "        self.model.compile(optimizer='adam',loss='mse')\n",
    "        \n",
    "        X = np.array(self.data['variables_history'])\n",
    "        y = self.data['rating_history']\n",
    "        self.model.fit(X, y, epochs=50, verbose=False)\n",
    "        return\n",
    "    \n",
    "    def test(self, n_iter=500, online=True):\n",
    "        \"\"\"\n",
    "        test model's performance\n",
    "        ---------------------------\n",
    "        n_iter: 'int', times of applying \"req_predict\" function to get test data\n",
    "        \n",
    "        online: 'bool', \"True\" means after each time of prediction, update the model\n",
    "                        \"False\" means don't update model\n",
    "        \"\"\"\n",
    "        if self.n_model == 1:\n",
    "            next_X = [[self.data['next_user']], [self.data['next_item']], [self.data['next_variables']]]\n",
    "        else:\n",
    "            next_X = np.array(self.data['next_variables']).reshape(1,-1)\n",
    "        next_predict = self.model.predict(next_X)\n",
    "        mse, mae = 0, 0\n",
    "\n",
    "        for i in tqdm(range(n_iter)):\n",
    "            sleep(0.05)\n",
    "            test = req_predict(next_predict, envs='second', verbose=False)\n",
    "            if self.n_model == 1:\n",
    "                next_X = [[test['next_user']], [test['next_item']], [test['next_variables']]]\n",
    "            else:\n",
    "                next_X =  np.array(test['next_variables']).reshape(1,-1)\n",
    "            next_y = [test['rating']]\n",
    "            next_predict = self.model.predict(next_X)\n",
    "    \n",
    "            mse += (next_y - next_predict) ** 2\n",
    "            mae += np.abs(next_y - next_predict)\n",
    "            \n",
    "                        \n",
    "            if online:\n",
    "                self.model.fit(next_X,next_y,verbose=False)\n",
    "\n",
    "        print('mse: ', float(mse)/n_iter)\n",
    "        print('mae: ', float(mae)/n_iter)\n",
    "        return\n",
    "    \n",
    "    def predict(self, input_data):\n",
    "        \"\"\"\n",
    "        perdict a rating\n",
    "        \"\"\"\n",
    "        if self.n_model == 1:\n",
    "            pred = self.model.predict([[input_data['next_user']], [input_data['next_item']], [input_data['next_variables']]])\n",
    "        else:\n",
    "            pred = self.model.predict(np.array(input_data['next_variables']).reshape(1,-1))\n",
    "        return float(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:34<00:00, 14.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse:  2.4091898225345174\n",
      "mae:  1.2984950094223022\n"
     ]
    }
   ],
   "source": [
    "env = Env_2()\n",
    "env.fit_model_1()\n",
    "env.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:37<00:00, 13.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse:  2.0841696582958655\n",
      "mae:  1.258834035396576\n"
     ]
    }
   ],
   "source": [
    "env = Env_2()\n",
    "env.fit_model_2()\n",
    "env.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
